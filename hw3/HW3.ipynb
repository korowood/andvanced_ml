{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: \n",
    "# Домашнее задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "+ подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "+ возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "+ расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path) as f:\n",
    "        names = f.read().replace('\\n', ' ')\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_k = read_data('corpora/AnnaKarenina.txt')\n",
    "w_and_p = read_data('corpora/WarAndPeace.txt')\n",
    "w_and_p_eng = read_data('corpora/WarAndPeaceEng.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_k = re.sub('\\W+',' ', anna_k ).lower()\n",
    "w_and_p = re.sub('\\W+',' ', w_and_p ).lower()\n",
    "w_and_p_eng = re.sub('\\W+',' ', w_and_p_eng ).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть перваяi лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях 61 100 1 в 70 е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобн'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anna_k[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCipher:\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        \n",
    "    def get_sorted_frequency_dict(self):\n",
    "        \"\"\"\n",
    "        input: text\n",
    "        output: sorted dict freq symbol\n",
    "        \"\"\"\n",
    "        counts = dict(Counter(self.text)) \n",
    "        counts = {k: v/len(self.text) for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True )}        \n",
    "        return counts\n",
    "\n",
    "    def get_encode_dict(self):\n",
    "        freq_dict = self.get_sorted_frequency_dict()\n",
    "        shuffled_letters = list(freq_dict.keys())\n",
    "        random.shuffle(shuffled_letters)\n",
    "        return {list(freq_dict.keys())[i]:shuffled_letters[i] for i in range(len(shuffled_letters))}\n",
    "\n",
    "    def get_decode_dict(self, freq_letters_list):\n",
    "        freq_dict = self.get_sorted_frequency_dict()\n",
    "        decode_dict = {list(freq_dict.keys())[i]:freq_letters_list[i] for i in range(min(len(freq_dict),len(freq_letters_list)))}\n",
    "        return decode_dict\n",
    "\n",
    "    def encode(self):\n",
    "        encode_dict = self.get_encode_dict()\n",
    "        return ''.join([encode_dict[i] for i in self.text])\n",
    "\n",
    "    def decode(self, freq_dict):\n",
    "        decode_dict = self.get_decode_dict(freq_dict)\n",
    "        return ''.join([decode_dict[i] if i in decode_dict.keys() else '?' for i in self.text])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(original, decoded):\n",
    "    return sum([1 for i in range(len(original)) if original[i]==decoded[i]]) / len(original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получаем отсортированный словарь частотности символов Анны Корениной**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0.16759116836318097,\n",
       " 'о': 0.09513034595302555,\n",
       " 'е': 0.07242743491488532,\n",
       " 'а': 0.06859314466860275,\n",
       " 'н': 0.05748448067215471,\n",
       " 'и': 0.05498627598220739,\n",
       " 'т': 0.04957691600291936,\n",
       " 'с': 0.044003547274936064,\n",
       " 'л': 0.04153755858919674,\n",
       " 'в': 0.038988394038047686,\n",
       " 'р': 0.032971030197525106,\n",
       " 'к': 0.028385228434899656,\n",
       " 'д': 0.024385757948859728,\n",
       " 'м': 0.02373850913704454,\n",
       " 'у': 0.022333891353575917,\n",
       " 'п': 0.019969822390240075,\n",
       " 'я': 0.01783243694742231,\n",
       " 'ь': 0.016314770276460177,\n",
       " 'ы': 0.015354733351061899,\n",
       " 'г': 0.01504955992938252,\n",
       " 'б': 0.01447845803660441,\n",
       " 'ч': 0.013974716879897564,\n",
       " 'з': 0.01354302242351042,\n",
       " 'ж': 0.009383643407492622,\n",
       " 'й': 0.008705350082531545,\n",
       " 'ш': 0.007068777068765354,\n",
       " 'х': 0.006435000404164416,\n",
       " 'ю': 0.005161589619651997,\n",
       " 'э': 0.002939856820362389,\n",
       " 'щ': 0.0023746123828948247,\n",
       " 'ц': 0.002338881905500502,\n",
       " 'ф': 0.0010432127908080126,\n",
       " '1': 0.0004539527865672149,\n",
       " 'e': 0.00043169445638714497,\n",
       " 'i': 0.00043110871085609055,\n",
       " 'a': 0.0002905297834030175,\n",
       " '2': 0.0002905297834030175,\n",
       " '8': 0.0002477703596360412,\n",
       " 'ъ': 0.00024132715879444198,\n",
       " 'n': 0.00023429821242178833,\n",
       " 's': 0.00021906882861437207,\n",
       " '3': 0.00021203988224171845,\n",
       " 'x': 0.00019622475290324772,\n",
       " 'l': 0.00019329602524797537,\n",
       " '7': 0.0001827526056889949,\n",
       " 'r': 0.00017220918613001441,\n",
       " 't': 0.0001669374763505242,\n",
       " 'o': 0.00016400874869525184,\n",
       " 'm': 0.00015873703891576159,\n",
       " '6': 0.00014995085594994453,\n",
       " '0': 0.00014936511041889006,\n",
       " 'u': 0.00014467914617045428,\n",
       " '9': 0.00014409340063939983,\n",
       " '4': 0.00014116467298412746,\n",
       " '5': 0.00013999318192201853,\n",
       " 'd': 0.00011129165090034945,\n",
       " 'c': 0.00010426270452769581,\n",
       " 'v': 0.00010074823134136899,\n",
       " 'p': 7.02894637265365e-05,\n",
       " 'h': 5.388858885701132e-05,\n",
       " 'b': 4.334516929803084e-05,\n",
       " 'f': 4.21736782359219e-05,\n",
       " 'g': 3.338749527010484e-05,\n",
       " 'ó': 3.104451314588695e-05,\n",
       " 'é': 2.694429442850566e-05,\n",
       " 'z': 1.8743856993743067e-05,\n",
       " 'ё': 1.8158111462688595e-05,\n",
       " 'j': 1.6400874869525182e-05,\n",
       " 'q': 1.347214721425283e-05,\n",
       " 'y': 1.1714910621089417e-05,\n",
       " 'w': 9.371928496871533e-06,\n",
       " 'è': 9.371928496871533e-06,\n",
       " 'k': 8.200437434762591e-06,\n",
       " 'á': 6.443200841599179e-06,\n",
       " 'â': 2.928727655272354e-06,\n",
       " 'ç': 2.3429821242178834e-06,\n",
       " 'ý': 1.7572365931634125e-06,\n",
       " 'à': 1.7572365931634125e-06,\n",
       " 'ü': 1.1714910621089417e-06,\n",
       " 'î': 1.1714910621089417e-06,\n",
       " 'ê': 5.857455310544708e-07,\n",
       " 'ї': 5.857455310544708e-07,\n",
       " 'ä': 5.857455310544708e-07}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_1 = RandomCipher(anna_k)\n",
    "\n",
    "anna_k_freq_dict =  cipher_1.get_sorted_frequency_dict()\n",
    "\n",
    "anna_k_freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получаем отсортированный словарь частотности символов Войны и мир**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0.16387921415800855,\n",
       " 'о': 0.09032554752917281,\n",
       " 'а': 0.06663502624337284,\n",
       " 'е': 0.06267014711322899,\n",
       " 'и': 0.05282280232940334,\n",
       " 'н': 0.051763044673428085,\n",
       " 'т': 0.04513034724381943,\n",
       " 'с': 0.04145878073334051,\n",
       " 'л': 0.040204463952763406,\n",
       " 'в': 0.036588906887245615,\n",
       " 'р': 0.03621452796566326,\n",
       " 'к': 0.028488172426550246,\n",
       " 'д': 0.024153336173110454,\n",
       " 'м': 0.023494488228435997,\n",
       " 'у': 0.02277815690603826,\n",
       " 'п': 0.020409546957286903,\n",
       " 'я': 0.0183902590731616,\n",
       " 'г': 0.016474146482385765,\n",
       " 'ь': 0.015473346136895928,\n",
       " 'ы': 0.015082753954930084,\n",
       " 'з': 0.014152702382022738,\n",
       " 'б': 0.013722314015479242,\n",
       " 'ч': 0.010831931868932002,\n",
       " 'й': 0.009153122452859945,\n",
       " 'ж': 0.008047672881258502,\n",
       " 'ш': 0.007502317759268458,\n",
       " 'х': 0.006780090705822182,\n",
       " 'e': 0.006557526858739758,\n",
       " 'ю': 0.0051513950036627225,\n",
       " 'ц': 0.003211699488692725,\n",
       " 'n': 0.003045145086571441,\n",
       " 's': 0.003033353624474359,\n",
       " 'i': 0.002930178331124891,\n",
       " 'a': 0.00278131112214923,\n",
       " 'r': 0.002731197408236631,\n",
       " 'u': 0.002552851544018265,\n",
       " 'o': 0.002541060081921183,\n",
       " 't': 0.0024172497299018215,\n",
       " 'э': 0.0024010364695183336,\n",
       " 'щ': 0.0022315342018727788,\n",
       " 'l': 0.001933799783921457,\n",
       " 'ф': 0.0017819847094215256,\n",
       " 'm': 0.0016670179539749756,\n",
       " 'c': 0.0013574920739265715,\n",
       " 'd': 0.0012823215030576735,\n",
       " 'p': 0.0010700751853101964,\n",
       " 'v': 0.0009079425814753182,\n",
       " 'ё': 0.0006352650204802957,\n",
       " 'h': 0.0006131560290482668,\n",
       " 'é': 0.0005409333237036393,\n",
       " 'b': 0.00046723668559687647,\n",
       " 'q': 0.000430388366543495,\n",
       " 'f': 0.0004274405010192245,\n",
       " 'ъ': 0.0004171229716842777,\n",
       " 'g': 0.0003257391404318918,\n",
       " 'j': 0.0003198434093833507,\n",
       " 'z': 0.00026825576270861676,\n",
       " 'x': 0.00021814204879601803,\n",
       " 'è': 0.00021077238498534175,\n",
       " 'à': 0.00016213260383487826,\n",
       " '0': 0.00010317529334946798,\n",
       " 'ê': 8.990989849025067e-05,\n",
       " 'y': 8.843596572811541e-05,\n",
       " '1': 7.811843639316862e-05,\n",
       " 'k': 6.043124324754553e-05,\n",
       " 'w': 5.453551219900451e-05,\n",
       " '2': 3.832225181551668e-05,\n",
       " 'ç': 3.390045352911091e-05,\n",
       " '8': 2.9478655242705138e-05,\n",
       " 'â': 2.6530789718434623e-05,\n",
       " '5': 2.5056856956299368e-05,\n",
       " '3': 2.3582924194164112e-05,\n",
       " 'ô': 1.6213260383487828e-05,\n",
       " '7': 1.3265394859217312e-05,\n",
       " '6': 1.3265394859217312e-05,\n",
       " '9': 1.3265394859217312e-05,\n",
       " 'î': 1.1791462097082056e-05,\n",
       " '4': 8.843596572811542e-06,\n",
       " 'ö': 8.843596572811542e-06,\n",
       " 'ü': 5.895731048541028e-06,\n",
       " 'û': 2.947865524270514e-06,\n",
       " 'í': 1.473932762135257e-06,\n",
       " 'ä': 1.473932762135257e-06,\n",
       " 'å': 1.473932762135257e-06}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_2 = RandomCipher(w_and_p)\n",
    "\n",
    "wap_freq_dict =  cipher_2.get_sorted_frequency_dict()\n",
    "\n",
    "wap_freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шифруем Анну Каренину**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хфф3kхkо3фä4мм4äз4âýмем4änтемäенäа4сьрäнм4сýме ьрäânс4мnéäю0é4ä nюа nїnäм4mем4ý акäа 4éfýaä4ünâенсnсäüâ4нnaäéаýäаm4а юеéьýäаýс0еäбnрnàеäтâчїäм4äтâчї4äз4àт4кäмýаm4а юеé4кäаýс0кäмýаm4а юеé4äбnäаénýсчäй näзмеї4änäéýmмьрäoýммnа крänäю2péеänäéýâýänäаýс0ýänämýюnéýmýазnсäтnа nема éýäюýéä nюа naânс4мäfеânзnїnäтьр4мекäm4а 0äбýâé4коäюýéä nюа naä4мм4äз4âýмем4äânс4мäfеânзnїnäтьр4мекä4мм4äз4âýмем4äбnâ4нею4äаnéâýсýммезnéäéаýтмýéмnа 02äаnтýâà4мекäмýnpьm4aм4кäаénpnт4äâ4азné4ммnа 0äбnéýа éné4мекäчтеéе ýю0мnäаnmý'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anna_k_encode = cipher_1.encode()\n",
    "anna_k_encode[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратно**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть перваяi лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно соче\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      " Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "cipher_3 = RandomCipher(anna_k_encode)\n",
    "anna_k_decoded = cipher_3.decode(list(anna_k_freq_dict.keys()))\n",
    "print(anna_k_decoded[:500])\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "print(f\"\\n Accuracy: {accuracy(anna_k, anna_k_decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Расшифруем Анну Коренину, зная только отсортированный по частотности список русских букв в Войне и Мире**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отсортированные по частотности символы только из Русского языка\n",
    "def get_only_rus_letters(frequency_dict):\n",
    "    return [' '] + [i for i in list(frequency_dict.keys()) if i in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'о',\n",
       " 'а',\n",
       " 'е',\n",
       " 'и',\n",
       " 'н',\n",
       " 'т',\n",
       " 'с',\n",
       " 'л',\n",
       " 'в',\n",
       " 'р',\n",
       " 'к',\n",
       " 'д',\n",
       " 'м',\n",
       " 'у',\n",
       " 'п',\n",
       " 'я',\n",
       " 'г',\n",
       " 'ь',\n",
       " 'ы',\n",
       " 'з',\n",
       " 'б',\n",
       " 'ч',\n",
       " 'й',\n",
       " 'ж',\n",
       " 'ш',\n",
       " 'х',\n",
       " 'ю',\n",
       " 'ц',\n",
       " 'э',\n",
       " 'щ',\n",
       " 'ф',\n",
       " 'ё',\n",
       " 'ъ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_freq_dict = get_only_rus_letters(wap_freq_dict)\n",
    "ru_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?????????? еиие кераиние одни нч семьх чиемаинтьх ромеиов лгве толстоыо иебниеатся стевшаж ефорнчмом фречож вса сбестлнвьа самгн похойн друы ие друые кейдея иасбестлнвея самгя иасбестлнве по своаму цто киные о вабиьх щаииостях о люзвн о вара о самга о баловабаском достониства лав толстожромеи шнрокоыо дьхеиня бестг парвея? лав толстож еиие кераиние ромеи шнрокоыо дьхеиня еиие кераиние поречнле соврамаиинков всадиавиостгю содарйеиня иаозьбежиея свозоде ресковеииостг поваствовеиня уднвнталгио собателнсг в цтом ромеиа с щалгиостгю худойастваииоыо вчыляде евторе ие йнчиг ои вьступел чдасг кек худойинк н мьслнталг н иечиебаина нскусстве вндал иа в том бтозь иаоспорнмо речрашнтг вопрос е в том бтозь честевнтг люзнтг йнчиг в засбнслаииьх инкоыде иа нстоэнмьх всах аа проявлаинях ?ё ё?? ё в ?? а ыодь одни местнтьж пнсеталг по внднмому ыоиберов скечел достоавскому цто ваэг иасльхеииея цто ваэг парвея кто у иес нч пнсеталаж мойат поревиятгся с цтнм е в авропа кто прадстевнт хотг бто инзудг подози\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      " Accuracy: 0.6261531865142634\n"
     ]
    }
   ],
   "source": [
    "decoded = cipher_3.decode(ru_freq_dict)\n",
    "print(decoded[:1000])\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "print(f\"\\n Accuracy: {accuracy(anna_k, decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Слишком большой скор, наверное из-за того, что я взял много больше 2-3х предложений**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "+ подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "+ проведите тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram:\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.length = len(self.text)\n",
    "\n",
    "    def get_sorted_frequency_dict(self):\n",
    "        counts = Counter()\n",
    "        for i in range(0, self.length - 1):\n",
    "            counts[self.text[i:i+2]] += 1\n",
    "        count_sum = sum(counts.values())\n",
    "        counts = dict(counts) \n",
    "        counts = {k: v/count_sum for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True )}        \n",
    "        return counts\n",
    "\n",
    "    def get_encode_dict(self):\n",
    "        freq_dict = self.get_sorted_frequency_dict()\n",
    "        shuffled_letters = list(freq_dict.keys())\n",
    "        random.shuffle(shuffled_letters)\n",
    "        return {list(freq_dict.keys())[i]:shuffled_letters[i] for i in range(len(shuffled_letters))}\n",
    "\n",
    "    def get_decode_dict(self, freq_letters_list):\n",
    "        freq_dict = self.get_sorted_frequency_dict()\n",
    "        decode_dict = {list(freq_dict.keys())[i]:freq_letters_list[i] for i in range(min(len(freq_dict),len(freq_letters_list)))}\n",
    "        return decode_dict\n",
    "\n",
    "    def encode(self):\n",
    "        encode_dict = self.get_encode_dict()\n",
    "        return ''.join([encode_dict[self.text[i:i+2]] for i in range(0, len(self.text) - 1)])\n",
    "\n",
    "    def decode(self, freq_dict):\n",
    "        decode_dict = self.get_decode_dict(freq_dict)\n",
    "        return ''.join([decode_dict[self.text[i:i+2]] if self.text[i:i+2] in decode_dict.keys() else '??' for i in range(0, self.length - 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зашифруем биграмами Анну Каренину**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бил  цтяutяiоасэьяsceèмсищirgrd мшдщптйт33фьirgrтгóиp фьахрпд ьн i24дищилмупешз irдидлйт332 бьлмупlà ktéрчмсéuззшксeчрx óзgrйчkaршlkînkayeгюдаacirlèttфьirе вв сфчьк iînксчкчаокéteueè82ilivчмд юшэсtéсжchс ыйунжирсeuеацалжлб iбómpéсînкд41ждvéféлб iлжьтуд92мф6 няцвмщuoицмфérбсеср saacirgrérбсеср 04grd мшраnrяхвзькacub16бómpéсînкд41ждóзвзьк iлжьтудstькacub16бómpéсînкд41ждóзgr6 няда iркьоasьтуяa igèskaдаd оч33 и04grтгдаеаэшснтптылмуп60poйтищéuзоîn70еиуптгдасeicаш эримфтгдаеаэшпкптлбтгда iлжьтуд68лбтг'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = Bigram(anna_k)\n",
    "\n",
    "anna_k_encode_bigram = bigram.encode()\n",
    "\n",
    "anna_k_encode_bigram[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Расшифруем Анну Коренину обучив частотности на Войне и Мире**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_wap = Bigram(w_and_p)\n",
    "wap_freq_dict = bigram_wap.get_sorted_frequency_dict()\n",
    "\n",
    "ru_freq_dict = get_only_rus_letters(wap_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_3 = Bigram(anna_k_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??????????????????????????зиноуф????????????зиногд????????кл????ту??????????????зи??????????????????????????йк????????????нолммн????рсмн???? дези??????зи????????абтурс??????????????????????????????????????????????ий????стту??????рс??????????стту????????проп??????????пр??????????дезино??????????ноуф??????????абдебв????????рс??????????абту????????абдебв????????рс????????нооп?? ту????????????????мн уф????????ногд ий????????????????????йк??рс??????гд ??????????пргд ий??????стгд ту????????стгд ????????????????????????????????рсмн??????рс????ст????????лммн????рсмн?????????????????????????????? ??????????????аб??????рс??чшоп??????????????????????лммн????рсмн??????????зиноуф????????????зино???????????????????????????? ??????????????аб??????зиноуф????????????зинооп??????????????ноту??????????????????????????ий????????бв????йк??рс??????ту??????????????????абдебв??????????????зи??абту????????????но??????????????????йк??рс??чшоп????????рс??????????????аб????????????????????йк ту??????????вг??????ч\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " Accuracy: 0.011240456740935295\n"
     ]
    }
   ],
   "source": [
    "decoded = bigram_3.decode(ru_freq_dict)\n",
    "print(decoded[:1000])\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "print(f\"\\n Accuracy: {accuracy(anna_k, decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Совсем как то мимо**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "+ предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "+ реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_cahracters = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "wap_rus_only = ''.join([i for i in w_and_p if i in rus_cahracters])\n",
    "anna_k_rus_only = ''.join([i for i in anna_k if i in rus_cahracters])\n",
    "emdedings = {c: i for i, c in enumerate(rus_cahracters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_matrix(text, matrix_of_transitions):\n",
    "    for i in range(len(text)-1):\n",
    "        matrix_of_transitions[emdedings[text[i]], emdedings[text[i+1]]] += 1\n",
    "    matrix_of_transitions = np.clip(matrix_of_transitions, 1, None)\n",
    "    matrix_of_transitions = (np.log(matrix_of_transitions).T - np.log(matrix_of_transitions.sum(axis=1))).T\n",
    "    return matrix_of_transitions\n",
    "\n",
    "\n",
    "def calculate_log_likelihood(text, permutation):\n",
    "    text = text.translate(str.maketrans(rus_cahracters, ''.join(permutation)))\n",
    "    return sum([matrix_of_transitions[emdedings[text[i]], emdedings[text[i+1]]] for i in range(len(text) - 1)])\n",
    "\n",
    "def decode_mcmc(text, iterations):\n",
    "    permutation = np.array(list(rus_cahracters))\n",
    "    random.shuffle(permutation)\n",
    "    log_likelihood = calculate_log_likelihood(text, permutation)\n",
    "    log_likelihood_best = log_likelihood\n",
    "    permutation_best = permutation.copy()\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        swap = random.sample(range(len(rus_cahracters)), 2)\n",
    "        permutation[swap[0]], permutation[swap[1]] = permutation[swap[1]], permutation[swap[0]]\n",
    "        log_likelihood_new = calculate_log_likelihood(text, permutation)\n",
    "        if log_likelihood_new >= log_likelihood:\n",
    "            log_likelihood = log_likelihood_new\n",
    "            if log_likelihood_new > log_likelihood_best:\n",
    "                log_likelihood_best = log_likelihood_new\n",
    "                permutation_best = permutation.copy()\n",
    "        else:\n",
    "            if random.random() < np.exp(log_likelihood_new - log_likelihood):\n",
    "                log_likelihood = log_likelihood_new\n",
    "            else:\n",
    "                permutation[swap[0]], permutation[swap[1]] = permutation[swap[1]], permutation[swap[0]]\n",
    "    return text.translate(str.maketrans(rus_cahracters, ''.join(permutation_best)))\n",
    "\n",
    "def encode(text):\n",
    "    encode_dict = get_encode_dict(text)\n",
    "    return ''.join([encode_dict[i] for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ьлттльчлдштетльаметьекьуляэньктляштеыэньдаялтаиь рильыа уыасаьтлхетлшыуюьуылившцьлёадекяаяьёдлкацьиушьухлуы еиэшьушяреьпанажеьмдбсьтльмдбсльчлжмлюьтшухлуы еилюьушярюьтшухлуы еильпаьуиашябьъыаьчтесльаьишхтэньфшттауыюньаь щзиеьаьишдшьаьушяршьаьхш аишхшучаяьмауыаетуыишь шиьыа уыацдаялтьведачасаьмэнлтеюьхлуырьпшдилюь шиьыа уыацьлттльчлдштетльдаялтьведачасаьмэнлтеюьлттльчлдштетльпадлке льуаидшяшттечаиьиушмтшитауырщьуамшджлтеюьтшазэхлцтлюьуиазамльдлучаилттауырьпаишуыиаилтеюьбмеиеыш ртаьуахшыл еурьиьъыаяьдаялтшьуьфш ртауырщьнбмажшуыишттасаьикс юмльлиыадльтльжектрьатьиэуыбпл ькмшурьчлчьнбмажтечьеьяэу еыш рьеьтлктлхштешьеучбууыильиемш ьтшьиьыаяьхыазэьтшаупадеяаьдлкдшвеырьиапдауьльиьыаяьхыазэьклуылиеырь щзеырьжектрьиьзшухеу шттэньтечасмльтшьеуыагеяэньиушньшшьпдаюи штеюнььььиььшьсамэьаметьялуыеыэцьпеулыш рьпаьиемеяаябьсатхлдаиьучлкл ьмауыашиучаябьъыаьишгрьтшу энлттлюьъыаьишгрьпшдилюьчыаьбьтлуьекьпеулыш шцьяажшыьпадлитюыруюьуьъыеяьльиьшидапшьчыаьпдшмуылиеыьнаырьхыаьтезбмрьпамазташььёьяьмауыашиучец'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_ = RandomCipher(anna_k_rus_only)\n",
    "\n",
    "encoded = cipher_.encode()[:1000]\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:53<00:00, 1879.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть первая лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях    в  е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобное  ф м достоевский'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_of_transitions = get_transitions_matrix(wap_rus_only, np.zeros((len(emdedings), len(emdedings))))\n",
    "decoded = decode_mcmc(encoded, 100000)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: {accuracy(anna_k_rus_only[:1000], decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выглядит круто!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "tmp = RandomCipher(msg1)\n",
    "encoded_cahracters = tmp.get_sorted_frequency_dict()\n",
    "print(len(set(encoded_cahracters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' оаеинтслвркдмупягьызбчйжшхю'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_2 = RandomCipher(w_and_p)\n",
    "\n",
    "wap_freq_dict =  cipher_2.get_sorted_frequency_dict()\n",
    "\n",
    "\n",
    "rus_top_frequent_chars = ''.join(get_only_rus_letters(wap_freq_dict)[:len(set(msg1))])\n",
    "rus_top_frequent_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_of_transitions = get_transitions_matrix(\n",
    "    wap_rus_only + anna_k_rus_only, np.zeros((len(emdedings), len(emdedings))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'олие рд реяесо навгтиундь еие памсе навгтиундь соклс з шсаыа лаабйонеч касавдь иоыка пваместсу лкавоо рлоыа рд рло ляоитие пвтреиуна е паизмесо гтклегтиундь бтии жт палиояноо мосровсао жтятнео кзвлт хасч каномна ч немоыа но абойтю'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_to_russian = str.maketrans(encoded_cahracters, rus_top_frequent_chars)\n",
    "message = msg1.translate(switch_to_russian)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [01:56<00:00, 7730.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode_mcmc(message, 900000)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
